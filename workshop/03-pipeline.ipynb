{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c20e55-2169-4ab7-91bc-0c85d2eed3ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e2a45b-2923-47ba-a0ca-551b09aa40bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pathlib\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from platformdirs import site_config_dir, user_config_dir\n",
    "from datetime import datetime, timezone, date\n",
    "from time import gmtime, strftime, sleep\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sagemaker import Model\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.feature_store.feature_store import FeatureStore\n",
    "from sagemaker.feature_store.inputs import TableFormatEnum\n",
    "# from sagemaker.feature_store.feature_processor import CSVDataSource, feature_processor, to_pipeline\n",
    "from sagemaker.remote_function import remote\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.drift_check_baselines import DriftCheckBaselines\n",
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.check_job_config import CheckJobConfig\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.workflow.fail_step import FailStep\n",
    "from sagemaker.workflow.function_step import step\n",
    "from sagemaker.workflow.step_outputs import get_step\n",
    "from sagemaker.workflow.pipeline_experiment_config import PipelineExperimentConfig\n",
    "from sagemaker.workflow.pipeline_definition_config import PipelineDefinitionConfig\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.steps import (\n",
    "    ProcessingStep,\n",
    "    TrainingStep,\n",
    "    CreateModelStep,\n",
    "    CacheConfig\n",
    ")\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterFloat,\n",
    "    ParameterString,\n",
    "    ParameterBoolean\n",
    ")\n",
    "from sagemaker.workflow.clarify_check_step import (\n",
    "    ModelBiasCheckConfig,\n",
    "    ClarifyCheckStep,\n",
    "    ModelExplainabilityCheckConfig\n",
    ")\n",
    "from sagemaker.workflow.conditions import (\n",
    "    ConditionGreaterThan,\n",
    "    ConditionGreaterThanOrEqualTo\n",
    ")\n",
    "\n",
    "from sagemaker.workflow.functions import (\n",
    "    Join,\n",
    "    JsonGet\n",
    ")\n",
    "from sagemaker.workflow.lambda_step import (\n",
    "    LambdaStep,\n",
    "    LambdaOutput,\n",
    "    LambdaOutputTypeEnum,\n",
    ")\n",
    "from sagemaker.model_metrics import (\n",
    "    MetricsSource,\n",
    "    ModelMetrics,\n",
    "    FileSource\n",
    ")\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput,\n",
    "    ProcessingOutput,\n",
    "    ScriptProcessor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fe2ade6-e16d-4dc8-83ae-292754a06335",
   "metadata": {},
   "outputs": [],
   "source": [
    "boto_session = boto3.Session()\n",
    "client_sagemaker = boto_session.client(\"sagemaker\")\n",
    "client_s3 = boto_session.client(\"s3\")\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region_name = boto_session.region_name\n",
    "sagemaker_role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17d62ffd-f0e0-46cb-839a-44ffdff2f3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "bucket_name                         -> 'sagemaker-us-east-1-891377318910'\n",
      "bucket_prefix                       -> 'from-idea-to-production/xgboost'\n",
      "col_target                          -> 'y'\n",
      "dataset_file_local_path             -> 'data/bank-additional/bank-additional-full.csv'\n",
      "dataset_raw                         -> 'bank-additional-full.csv'\n",
      "domain_id                           -> 'd-ehxji4qaadry'\n",
      "experiment_name                     -> 'itau-experiment-2024-10-13-18-09-47'\n",
      "initialized                         -> True\n",
      "input_s3_url                        -> 's3://sagemaker-us-east-1-891377318910/workshop_v2\n",
      "loca_transformed_path               -> './data/transformed'\n",
      "local_prefix                        -> './data/raw'\n",
      "output_s3_url                       -> 's3://sagemaker-us-east-1-891377318910/workshop_v2\n",
      "region                              -> 'us-east-1'\n",
      "region_name                         -> 'us-east-1'\n",
      "s3_data_raw_prefix                  -> 'data/raw'\n",
      "s3_prefix                           -> 'workshop_v2'\n",
      "sagemaker_role                      -> 'arn:aws:iam::891377318910:role/service-role/SageM\n",
      "target_col                          -> 'y'\n",
      "user_profile_name                   -> None\n"
     ]
    }
   ],
   "source": [
    "%store -r \n",
    "\n",
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8455e39d-f3b6-4262-b090-fc4bccfbb38e",
   "metadata": {},
   "source": [
    "## Set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f5b2586-c666-46ed-abe5-6c0e07b59fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"itau-project\"\n",
    "\n",
    "current_timestamp        = strftime('%Y-%m-%d-%H-%M-%S', gmtime())\n",
    "pipeline_name            = f\"{project}-pipeline-{current_timestamp}\"\n",
    "pipeline_model_name      = f\"{project}-model-xgb\"\n",
    "model_package_group_name = f\"{project}-model-group-{current_timestamp}\"\n",
    "endpoint_config_name     = f\"{project}-endpoint-config\"\n",
    "endpoint_name            = f\"{project}-endpoint\"\n",
    "model_approval_status    = \"PendingManualApproval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac465205-125c-4b91-9dde-2d4e361e8e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_instance_type = \"ml.c5.xlarge\"\n",
    "process_instance_count = 1\n",
    "train_instance_type = \"ml.m5.xlarge\"\n",
    "train_instance_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae0de15d-602e-461c-ae83-c083775d50f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_s3_prefix = f\"s3://{bucket_name}/{bucket_prefix}\"\n",
    "train_s3_url = f\"{output_s3_prefix}/train\"\n",
    "validation_s3_url = f\"{output_s3_prefix}/validation\"\n",
    "test_s3_url = f\"{output_s3_prefix}/test\"\n",
    "baseline_s3_url = f\"{output_s3_prefix}/baseline\"\n",
    "\n",
    "evaluation_s3_url = f\"{output_s3_prefix}/evaluation\"\n",
    "prediction_baseline_s3_url = f\"{output_s3_prefix}/prediction_baseline\"\n",
    "\n",
    "output_s3_url = f\"{output_s3_prefix}/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4024926-7714-46df-bff4-af493fe09a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train S3 url:                     s3://sagemaker-us-east-1-891377318910/from-idea-to-production/xgboost/train\n",
      "Validation S3 url:                s3://sagemaker-us-east-1-891377318910/from-idea-to-production/xgboost/validation\n",
      "Test S3 url:                      s3://sagemaker-us-east-1-891377318910/from-idea-to-production/xgboost/test\n",
      "Data baseline S3 url:             s3://sagemaker-us-east-1-891377318910/from-idea-to-production/xgboost/baseline\n",
      "Evaluation metrics S3 url:        s3://sagemaker-us-east-1-891377318910/from-idea-to-production/xgboost/evaluation\n",
      "Model prediction baseline S3 url: s3://sagemaker-us-east-1-891377318910/from-idea-to-production/xgboost/prediction_baseline\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train S3 url:                     {train_s3_url}\")\n",
    "print(f\"Validation S3 url:                {validation_s3_url}\")\n",
    "print(f\"Test S3 url:                      {test_s3_url}\")\n",
    "print(f\"Data baseline S3 url:             {baseline_s3_url}\")\n",
    "print(f\"Evaluation metrics S3 url:        {evaluation_s3_url}\")\n",
    "print(f\"Model prediction baseline S3 url: {prediction_baseline_s3_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef8062-cbe6-41ff-8281-42869907bb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %store train_s3_url\n",
    "# %store validation_s3_url\n",
    "# %store test_s3_url\n",
    "# %store baseline_s3_url\n",
    "# %store pipeline_name\n",
    "# %store model_package_group_name\n",
    "# %store evaluation_s3_url\n",
    "# %store prediction_baseline_s3_url\n",
    "# %store output_s3_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8004e583-0c13-427e-a095-e8b7f4db44ac",
   "metadata": {},
   "source": [
    "## Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5eb7d7f-129a-46a1-916b-833d44658191",
   "metadata": {},
   "outputs": [],
   "source": [
    "skprocessor_framework_version = \"0.23-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b175176-cb72-422e-8e7b-5d3518b8107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set processing instance type\n",
    "process_instance_type_param = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=process_instance_type,\n",
    ")\n",
    "\n",
    "# Set training instance type\n",
    "train_instance_type_param = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=train_instance_type,\n",
    ")\n",
    "\n",
    "# Set training instance count\n",
    "train_instance_count_param = ParameterInteger(\n",
    "    name=\"TrainingInstanceCount\",\n",
    "    default_value=train_instance_count\n",
    ")\n",
    "\n",
    "# Set model approval status for the model registry\n",
    "model_approval_status_param = ParameterString(\n",
    "    name=\"ModelApprovalStatus\",\n",
    "    default_value=model_approval_status\n",
    ")\n",
    "\n",
    "# Minimal threshold for model performance on the test dataset\n",
    "test_score_threshold_param = ParameterFloat(\n",
    "    name=\"TestScoreThreshold\",\n",
    "    default_value=0.75\n",
    ")\n",
    "\n",
    "# Parametrize the S3 url for input dataset\n",
    "input_s3_url_param = ParameterString(\n",
    "    name=\"InputDataUrl\",\n",
    "    default_value=input_s3_url,\n",
    ")\n",
    "\n",
    "# Model package group name\n",
    "model_package_group_name_param = ParameterString(\n",
    "    name=\"ModelPackageGroupName\",\n",
    "    default_value=model_package_group_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3e81b3-cdf8-455c-b0bf-c190bbd0088c",
   "metadata": {},
   "source": [
    "## Build the pipeline steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ac8e1d-366e-4b59-be15-c621e77886b6",
   "metadata": {},
   "source": [
    "You create a pipeline with the following:\n",
    "| Step | Description |\n",
    "|---|---|\n",
    "| **Data processing** | runs a SageMaker processing job for feature engineering and dataset split|\n",
    "| **Training** | runs a SageMaker training job using XGBoost algorithm |\n",
    "| **Evaluation** | evaluates the performance of the trained model |\n",
    "| **Condition** | checks if the performance of the model meets the specified threshold |\n",
    "| **Register model** | registers a version of the model in the SageMaker model registry |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54daf6cd-3113-4c40-8c53-8635a988dfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = PipelineSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8f3714-91e9-4716-91e0-731ed60c5195",
   "metadata": {},
   "source": [
    "## Processing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f61d5da6-b70b-4077-9279-39d20d9ae480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./code/preprocessing_pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./code/preprocessing_pipeline.py\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "\n",
    "def _parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # Data, model, and output directories\n",
    "    # model_dir is always passed in from SageMaker. By default this is a S3 path under the default bucket.\n",
    "    parser.add_argument('--filepath', type=str, default='/opt/ml/processing/input/')\n",
    "    parser.add_argument('--filename', type=str, default='bank-additional-full.csv')\n",
    "    parser.add_argument('--outputpath', type=str, default='/opt/ml/processing/output/')\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "\n",
    "def process_data(df_data):\n",
    "    target_col = \"y\"\n",
    "\n",
    "    # Indicator variable to capture when pdays takes a value of 999\n",
    "    df_data[\"no_previous_contact\"] = np.where(df_data[\"pdays\"] == 999, 1, 0)\n",
    "\n",
    "    # Indicator for individuals not actively employed\n",
    "    df_data[\"not_working\"] = np.where(\n",
    "        np.in1d(df_data[\"job\"], [\"student\", \"retired\", \"unemployed\"]), 1, 0\n",
    "    )\n",
    "\n",
    "    # remove unnecessary data\n",
    "    df_model_data = df_data.drop(\n",
    "        [\"duration\", \"emp.var.rate\", \"cons.price.idx\", \"cons.conf.idx\", \"euribor3m\", \"nr.employed\"],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    bins = [18, 30, 40, 50, 60, 70, 90]\n",
    "    labels = ['18-29', '30-39', '40-49', '50-59', '60-69', '70-plus']\n",
    "\n",
    "    df_model_data['age_range'] = pd.cut(df_model_data.age, bins, labels=labels, include_lowest=True)\n",
    "    df_model_data = pd.concat([df_model_data, pd.get_dummies(df_model_data['age_range'], prefix='age', dtype=int)], axis=1)\n",
    "    df_model_data.drop('age', axis=1, inplace=True)\n",
    "    df_model_data.drop('age_range', axis=1, inplace=True)\n",
    "\n",
    "    scaled_features = ['pdays', 'previous', 'campaign']\n",
    "    df_model_data[scaled_features] = MinMaxScaler().fit_transform(df_model_data[scaled_features])\n",
    "\n",
    "    df_model_data = pd.get_dummies(df_model_data, dtype=int)  # Convert categorical variables to sets of indicators\n",
    "\n",
    "    # Replace \"y_no\" and \"y_yes\" with a single label column, and bring it to the front:\n",
    "    df_model_data = pd.concat([\n",
    "            df_model_data[\"y_yes\"].rename(target_col),\n",
    "            df_model_data.drop([\"y_no\", \"y_yes\"], axis=1),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    return df_model_data\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # Process arguments\n",
    "    args, _ = _parse_args()\n",
    "    target_col = \"y\"\n",
    "\n",
    "    # process data\n",
    "    df_model_data = process_data(pd.read_csv(os.path.join(args.filepath, args.filename), sep=\";\"))\n",
    "\n",
    "    # Shuffle and splitting dataset\n",
    "    train_data, validation_data, test_data = np.split(\n",
    "        df_model_data.sample(frac=1, random_state=1729),\n",
    "        [int(0.7 * len(df_model_data)), int(0.9 * len(df_model_data))],\n",
    "    )\n",
    "\n",
    "    print(f\"Data split -> train:{train_data.shape} | validation:{validation_data.shape} | test:{test_data.shape}\")\n",
    "\n",
    "    # Save datasets locally\n",
    "    train_data.to_csv(os.path.join(args.outputpath, 'train/train.csv'), index=False, header=False)\n",
    "    validation_data.to_csv(os.path.join(args.outputpath, 'validation/validation.csv'), index=False, header=False)\n",
    "    test_data[target_col].to_csv(os.path.join(args.outputpath, 'test/test_y.csv'), index=False, header=False)\n",
    "    test_data.drop([target_col], axis=1).to_csv(os.path.join(args.outputpath, 'test/test_x.csv'), index=False, header=False)\n",
    "\n",
    "    # Save the baseline dataset for model monitoring\n",
    "    df_model_data.drop([target_col], axis=1).to_csv(os.path.join(args.outputpath, 'baseline/baseline.csv'), index=False, header=False)\n",
    "\n",
    "    print(\"## Processing complete. Exiting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfd781af-c240-4afa-b967-6f51f9b81633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n"
     ]
    }
   ],
   "source": [
    "sklearn_processor = SKLearnProcessor(\n",
    "        framework_version=skprocessor_framework_version,\n",
    "        role=sagemaker_role,\n",
    "        instance_type=process_instance_type_param,\n",
    "        instance_count=process_instance_count,\n",
    "        base_job_name=f\"{project}-preprocess\",\n",
    "        sagemaker_session=session,\n",
    "    )\n",
    "\n",
    "processing_inputs = [\n",
    "    ProcessingInput(\n",
    "        source=input_s3_url_param,\n",
    "        destination=\"/opt/ml/processing/input\"\n",
    "    )\n",
    "]\n",
    "\n",
    "processing_outputs = [\n",
    "    ProcessingOutput(\n",
    "        output_name=\"train_data\",\n",
    "        source=\"/opt/ml/processing/output/train\",\n",
    "        destination=train_s3_url\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        output_name=\"validation_data\",\n",
    "        source=\"/opt/ml/processing/output/validation\",\n",
    "        destination=validation_s3_url\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        output_name=\"test_data\",\n",
    "        source=\"/opt/ml/processing/output/test\",\n",
    "        destination=test_s3_url\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        output_name=\"baseline_data\",\n",
    "        source=\"/opt/ml/processing/output/baseline\",\n",
    "        destination=baseline_s3_url\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddae8f6b-090c-43d9-8dbf-b173e6c79bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "processor_args = sklearn_processor.run(\n",
    "    inputs=processing_inputs,\n",
    "    outputs=processing_outputs,\n",
    "    code='./code/preprocessing_pipeline.py',\n",
    "    # arguments = ['arg1', 'arg2'],\n",
    ")\n",
    "\n",
    "# Define processing step\n",
    "step_process = ProcessingStep(\n",
    "    name=f\"{project}-preprocess\",\n",
    "    step_args=processor_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a41b54-13ec-4e95-bbf4-a3afc3c460a3",
   "metadata": {},
   "source": [
    "## Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a512c34-1c33-483b-9812-9a940c58e50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "xgboost_image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region_name,\n",
    "    version=\"1.7-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75d4c3be-0b6c-4178-af6d-2322b62dc07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Instantiate an XGBoost estimator object\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=xgboost_image_uri,\n",
    "    role=sagemaker_role,\n",
    "    instance_type=train_instance_type_param,\n",
    "    instance_count=train_instance_count_param,\n",
    "    output_path=output_s3_url,\n",
    "    sagemaker_session=session,\n",
    "    base_job_name=f\"{project}-train\",\n",
    ")\n",
    "\n",
    "# Define algorithm hyperparameters\n",
    "estimator.set_hyperparameters(\n",
    "    num_round=100,            # the number of rounds to run the training\n",
    "    max_depth=3,              # maximum depth of a tree\n",
    "    eta=0.5,                  # step size shrinkage used in updates to prevent overfitting\n",
    "    alpha=2.5,                # L1 regularization term on weights\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",        # evaluation metrics for validation data\n",
    "    subsample=0.8,            # subsample ratio of the training instance\n",
    "    colsample_bytree=0.8,     # subsample ratio of columns when constructing each tree\n",
    "    min_child_weight=3,       # minimum sum of instance weight (hessian) needed in a child\n",
    "    early_stopping_rounds=10, # the model trains until the validation score stops improving\n",
    "    verbosity=1,              # verbosity of printing messages\n",
    ")\n",
    "\n",
    "training_inputs = {\n",
    "    \"train\": TrainingInput(\n",
    "        s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train_data\"].S3Output.S3Uri,\n",
    "        content_type=\"text/csv\",\n",
    "    ),\n",
    "    \"validation\": TrainingInput(\n",
    "        s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"validation_data\"].S3Output.S3Uri,\n",
    "        content_type=\"text/csv\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "training_args = estimator.fit(training_inputs)\n",
    "\n",
    "# Define training step\n",
    "step_train = TrainingStep(\n",
    "    name=f\"{project}-train\",\n",
    "    step_args=training_args\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3b9e20-4fa0-408d-8143-cc2a68106cdf",
   "metadata": {},
   "source": [
    "## Evaluation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b66daecd-13be-44c2-987d-2438d1147eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./code/evaluation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./code/evaluation.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import pickle as pkl\n",
    "import tarfile\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import datetime as dt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":   \n",
    "    # All paths are local for the processing container\n",
    "    model_path = \"/opt/ml/processing/model/model.tar.gz\"\n",
    "    test_x_path = \"/opt/ml/processing/test/test_x.csv\"\n",
    "    test_y_path = \"/opt/ml/processing/test/test_y.csv\"\n",
    "    output_dir = \"/opt/ml/processing/evaluation\"\n",
    "    output_prediction_path = \"/opt/ml/processing/output/\"\n",
    "\n",
    "    # Read model tar file\n",
    "    with tarfile.open(model_path, \"r:gz\") as t:\n",
    "        t.extractall(path=\".\")\n",
    "\n",
    "    # Load model\n",
    "    model = xgb.Booster()\n",
    "    model.load_model(\"xgboost-model\")\n",
    "\n",
    "    # Read test data\n",
    "    X_test = xgb.DMatrix(pd.read_csv(test_x_path, header=None).values)\n",
    "    y_test = pd.read_csv(test_y_path, header=None).to_numpy()\n",
    "\n",
    "    # Run predictions\n",
    "    probability = model.predict(X_test)\n",
    "\n",
    "    # Evaluate predictions\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probability)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    report_dict = {\n",
    "        \"classification_metrics\": {\n",
    "            \"auc_score\": {\n",
    "                \"value\": auc_score,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Save evaluation report\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    with open(f\"{output_dir}/evaluation.json\", \"w\") as f:\n",
    "        f.write(json.dumps(report_dict))\n",
    "\n",
    "    # Save prediction baseline file - you need it later for the model quality monitoring\n",
    "    pd.DataFrame({\n",
    "        \"prediction\": np.array(np.round(probability), dtype=int),\n",
    "        \"probability\": probability,\n",
    "        \"label\": y_test.squeeze()}\n",
    "    ).to_csv(\n",
    "        os.path.join(output_prediction_path, 'prediction_baseline/prediction_baseline.csv'), \n",
    "        index=False,\n",
    "        header=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5f22038-444d-4958-9a9e-e8e4a7dfea62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "script_processor = ScriptProcessor(\n",
    "    image_uri=xgboost_image_uri,\n",
    "    role=sagemaker_role,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=process_instance_type_param,\n",
    "    instance_count=process_instance_count,\n",
    "    base_job_name=f\"{project}-evaluate\",\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "\n",
    "eval_inputs = [\n",
    "    ProcessingInput(\n",
    "        source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "        destination=\"/opt/ml/processing/model\"\n",
    "    ),\n",
    "    ProcessingInput(\n",
    "        source=step_process.properties.ProcessingOutputConfig.Outputs[\"test_data\"].S3Output.S3Uri,\n",
    "        destination=\"/opt/ml/processing/test\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "eval_outputs = [\n",
    "    ProcessingOutput(\n",
    "        output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\",\n",
    "        destination=evaluation_s3_url),\n",
    "    ProcessingOutput(\n",
    "        output_name=\"prediction_baseline_data\", source=\"/opt/ml/processing/output/prediction_baseline\",\n",
    "        destination=prediction_baseline_s3_url),\n",
    "]\n",
    "\n",
    "eval_args = script_processor.run(\n",
    "    inputs=eval_inputs,\n",
    "    outputs=eval_outputs,\n",
    "    code=\"./code/evaluation.py\",\n",
    ")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"ModelEvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name=f\"{project}-evaluate\",\n",
    "    step_args=eval_args,\n",
    "    property_files=[evaluation_report]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91053ac3-6b2b-4c2c-8b25-70dc93bc43ca",
   "metadata": {},
   "source": [
    "## Register step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41cd0de0-4ef1-44ab-8d88-70bfb7133e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    }
   ],
   "source": [
    "model = Model(\n",
    "    image_uri=xgboost_image_uri,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    name=\"from-idea-to-prod-xgboost-model\",\n",
    "    sagemaker_session=session,\n",
    "    role=sagemaker_role,\n",
    ")\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=\"{}/evaluation.json\".format(\n",
    "            step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "\n",
    "register_args = model.register(\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.m5.xlarge\", \"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\", \"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name_param,\n",
    "    approval_status=model_approval_status_param,\n",
    "    model_metrics=model_metrics,\n",
    ")\n",
    "\n",
    "step_register = ModelStep(\n",
    "    name=f\"{project}-register\",\n",
    "    step_args=register_args\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67541bf-3c59-42a2-be0e-17c59c96b41d",
   "metadata": {},
   "source": [
    "## Fail step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b088cbff-78ff-41a7-bf3c-1ae21d50650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_fail = FailStep(\n",
    "    name=f\"{project}-fail\",\n",
    "    error_message=Join(on=\" \", values=[\"Execution failed due to AUC Score >\", test_score_threshold_param]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f43107-bbc0-4827-a724-ae085be49b8c",
   "metadata": {},
   "source": [
    "## Condition step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "648c74f5-0305-4d0f-afa5-03ca9d9ca8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_lte = ConditionGreaterThan(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"classification_metrics.auc_score.value\",\n",
    "    ),\n",
    "    right=test_score_threshold_param,\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=f\"{project}-check-test-score\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_register],\n",
    "    else_steps=[step_fail],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b99df9-5abf-40a4-9d5b-5db3fe623b23",
   "metadata": {},
   "source": [
    "## Construct pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "585a6da7-fe0d-4dbd-94d5-c6ed77c04e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_def_config = PipelineDefinitionConfig(use_custom_job_prefix=True)\n",
    "\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        process_instance_type_param,\n",
    "        train_instance_type_param,\n",
    "        train_instance_count_param,\n",
    "        model_approval_status_param,\n",
    "        test_score_threshold_param,\n",
    "        input_s3_url_param,\n",
    "        model_package_group_name_param,\n",
    "    ],\n",
    "    steps=[step_process, step_train, step_eval, step_cond],\n",
    "    sagemaker_session=session,\n",
    "    pipeline_definition_config=pipeline_def_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6fa44bc3-a1a3-4048-ad26-b62042385754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itau-project-pipeline-2024-10-16-23-49-13\n"
     ]
    }
   ],
   "source": [
    "print(pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d190a095-e0ff-4451-8178-68f0bf9f9bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:891377318910:pipeline/itau-project-pipeline-2024-10-16-23-49-13',\n",
       " 'ResponseMetadata': {'RequestId': '11b12cfb-a9a6-4656-a9f7-5e2e56aaa5a0',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '11b12cfb-a9a6-4656-a9f7-5e2e56aaa5a0',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '109',\n",
       "   'date': 'Thu, 17 Oct 2024 00:03:26 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=sagemaker_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1fbe7e74-0439-4abd-83c6-8995b090b065",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_definition = json.loads(pipeline.describe()['PipelineDefinition'])\n",
    "# pipeline_definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b171ac6-06de-4f5b-a397-e871ae07a97b",
   "metadata": {},
   "source": [
    "# Execute the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f446ba41-f3cb-487b-bcf7-5c266e25608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution = pipeline.start(\n",
    "#     parameters=dict(\n",
    "#         ProcessingInstanceType=process_instance_type,\n",
    "#         TrainingInstanceType=train_instance_type,\n",
    "#         TrainingInstanceCount=train_instance_count,\n",
    "#         ModelApprovalStatus=\"PendingManualApproval\",\n",
    "#         TestScoreThreshold=0.75,\n",
    "#         InputDataUrl=input_s3_url\n",
    "#     )\n",
    "# )\n",
    "\n",
    "execution = pipeline.start(\n",
    "    parameters={\n",
    "        \"ProcessingInstanceType\": process_instance_type,\n",
    "        \"TrainingInstanceType\": train_instance_type,\n",
    "        \"TrainingInstanceCount\": train_instance_count,\n",
    "        \"ModelApprovalStatus\": \"PendingManualApproval\",\n",
    "        \"TestScoreThreshold\": 0.75,\n",
    "        \"InputDataUrl\": input_s3_url\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eaf7f983-306c-4f5c-9dca-c8d1a9c95f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'StepName': 'itau-project-register-RegisterModel',\n",
       "  'StartTime': datetime.datetime(2024, 10, 17, 0, 11, 45, 135000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2024, 10, 17, 0, 11, 47, 90000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'Metadata': {'RegisterModel': {'Arn': 'arn:aws:sagemaker:us-east-1:891377318910:model-package/itau-project-model-group-2024-10-16-23-49-13/1'}},\n",
       "  'AttemptCount': 1},\n",
       " {'StepName': 'itau-project-check-test-score',\n",
       "  'StartTime': datetime.datetime(2024, 10, 17, 0, 11, 44, 125000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2024, 10, 17, 0, 11, 44, 507000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'Metadata': {'Condition': {'Outcome': 'True'}},\n",
       "  'AttemptCount': 1},\n",
       " {'StepName': 'itau-project-evaluate',\n",
       "  'StartTime': datetime.datetime(2024, 10, 17, 0, 9, 8, 852000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2024, 10, 17, 0, 11, 43, 540000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:891377318910:processing-job/itau-project-evaluate-bqe1pis0w5s8-T8wvR0HF8V'}},\n",
       "  'AttemptCount': 1},\n",
       " {'StepName': 'itau-project-train',\n",
       "  'StartTime': datetime.datetime(2024, 10, 17, 0, 6, 34, 533000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2024, 10, 17, 0, 9, 8, 157000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'Metadata': {'TrainingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:891377318910:training-job/itau-project-train-bqe1pis0w5s8-L1aX2QbZal'}},\n",
       "  'AttemptCount': 1},\n",
       " {'StepName': 'itau-project-preprocess',\n",
       "  'StartTime': datetime.datetime(2024, 10, 17, 0, 4, 1, 72000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2024, 10, 17, 0, 6, 33, 781000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:891377318910:processing-job/itau-project-preprocess-bqe1pis0w5s8-2bEIf6oNJp'}},\n",
       "  'AttemptCount': 1}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep(5)\n",
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a49532-2f20-4cbf-8da6-42fb635c02cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abb82e9-2f71-47d1-bffe-0c6b571af16a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
