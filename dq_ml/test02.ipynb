{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Any\n",
    "from enum import Enum\n",
    "from collections import namedtuple\n",
    "from random import choice\n",
    "from abc import ABC, ABCMeta, abstractmethod\n",
    "from sklearn import datasets\n",
    "from pydantic import (\n",
    "    BaseModel,\n",
    "    ValidationError,\n",
    "    field_validator,\n",
    "    field_serializer,\n",
    "    model_validator,\n",
    "    computed_field,\n",
    "    ValidatorFunctionWrapHandler,\n",
    "    ValidationInfo,\n",
    "    Field,\n",
    "    ConfigDict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.context import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import udf\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import Row, Column\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "from pyspark.pandas.typedef import as_spark_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.iteritems = pd.DataFrame.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: park.sql.execution.arrow.pyspark.fallback.enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/08/16 09:22:45 WARN Utils: Your hostname, dell resolves to a loopback address: 127.0.1.1; using 192.168.15.6 instead (on interface wlp0s20f3)\n",
      "24/08/16 09:22:45 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/08/16 09:22:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"Testes\")\n",
    "    .config('spark.sql.adaptive.enabled', 'true')\n",
    "    .config('spark.sql.adaptive.optimizerEnabled', 'true')\n",
    "    .config('spark.sql.execution.arrow.enabled', 'true')\n",
    "    .config('spark.sql.execution.arrow.pyspark.enabled', 'true')\n",
    "    .config(\"spark.sql.parquet.datetimeRebaseModeInRead\", \"CORRECTED\")\n",
    "    .config(\"spark.sql.parquet.datetimeRebaseModeInWrite\", \"CORRECTED\")\n",
    "    .config(\"spark.sql.legacy.timeParserPolicy\", \"CORRECTED\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", \"true\")\n",
    "    .config(\"spark.sql.debug.maxToStringFields\", \"100000\")\n",
    "    .config(\"park.sql.execution.arrow.pyspark.fallback.enabled\", \"false\")\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = datasets.load_iris(as_frame=True) # classification\n",
    "df_iris = iris_data.frame\n",
    "\n",
    "# bcancer_data = datasets.load_breast_cancer(as_frame=True) # classification\n",
    "# df_bcancer = bcancer_data.frame\n",
    "\n",
    "# diabetes_data = datasets.load_diabetes(as_frame=True) # regression\n",
    "# df_diabetes = diabetes_data.frame\n",
    "\n",
    "# wine_data = datasets.load_wine(as_frame=True) # classification\n",
    "# df_wine = wine_data.frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = df_iris.rename({\n",
    "    \"sepal length (cm)\": \"sepal_length\",\n",
    "    \"sepal width (cm)\": \"sepal_width\",\n",
    "    \"petal length (cm)\": \"petal_length\",\n",
    "    \"petal width (cm)\": \"petal_width\",\n",
    "}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  target\n",
       "0           5.1          3.5           1.4          0.2       0\n",
       "1           4.9          3.0           1.4          0.2       0\n",
       "2           4.7          3.2           1.3          0.2       0\n",
       "3           4.6          3.1           1.5          0.2       0\n",
       "4           5.0          3.6           1.4          0.2       0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/39109045/numpy-where-with-multiple-conditions\n",
    "\n",
    "def energy_class(x: float):\n",
    "    if x > 6:\n",
    "        return 'high'\n",
    "    elif x > 5:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'low'\n",
    "\n",
    "\n",
    "dfp['tipo'] = pd.cut(dfp['sepal_length'], bins=[0, 5, 6, np.inf], labels=['low', 'medium', 'high'])\n",
    "# dfp['tipo'] = np.where(dfp['sepal_length'] > 7, 'high', np.where(dfp['sepal_length'] > 5, 'medium', 'low'))\n",
    "# dfp['tipo'] = dfp['sepal_length'].apply(energy_class)\n",
    "# dfp['tipo'] = np.select([dfp['sepal_length'] > 7, dfp['sepal_length'] > 5], ['high', 'medium'], default='low')\n",
    "# dfp['tipo'] = np.vectorize(lambda x: 'high' if x > 5 else ('medium' if x > 3 else 'low'))(dfp['sepal_length'])\n",
    "# dfp['tipo'] = dfp['sepal_length'].apply(lambda x: 'high' if x > 6 else ('medium' if x > 5 else 'low'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tipo\n",
       "high      61\n",
       "medium    57\n",
       "low       32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp['tipo'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suit():\n",
    "    return choice(('Spade', 'Heart', 'Diamond', 'Club'))\n",
    "\n",
    "dfp['suit'] = [suit() for _ in range(len(dfp))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>target</th>\n",
       "      <th>tipo</th>\n",
       "      <th>suit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>medium</td>\n",
       "      <td>Club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>Diamond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>Club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>Club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>low</td>\n",
       "      <td>Heart</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  target    tipo  \\\n",
       "0           5.1          3.5           1.4          0.2       0  medium   \n",
       "1           4.9          3.0           1.4          0.2       0     low   \n",
       "2           4.7          3.2           1.3          0.2       0     low   \n",
       "3           4.6          3.1           1.5          0.2       0     low   \n",
       "4           5.0          3.6           1.4          0.2       0     low   \n",
       "\n",
       "      suit  \n",
       "0     Club  \n",
       "1  Diamond  \n",
       "2     Club  \n",
       "3     Club  \n",
       "4    Heart  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(dfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricType(Enum):\n",
    "    COLUMN = \"COLUMN\"\n",
    "    TABLE = \"TABLE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricName(Enum):\n",
    "    MEAN = \"MEAN\"\n",
    "    DUPLICITY = \"DUPLICITY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricMetaClass(type):\n",
    "\n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        return super().__new__(cls, *args, **kwargs)\n",
    "    \n",
    "    def __call__(cls, *args, **kwargs):\n",
    "        print(\"MetaClass Mae\")\n",
    "        return cls.evaluate(*args, **kwargs)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def evaluate(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombineMeta(ABCMeta, MetricMetaClass):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricBase(ABC):\n",
    "\n",
    "    @classmethod\n",
    "    def all_metrics(cls) -> list:\n",
    "        return [subclass.name for subclass in cls.__subclasses__()]\n",
    "    \n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def name(self) -> str:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # @property\n",
    "    # @abstractmethod\n",
    "    # def type(self) -> str:\n",
    "    #     raise NotImplementedError\n",
    "\n",
    "    # @property\n",
    "    # @abstractmethod\n",
    "    # def schema(self) -> str:\n",
    "    #     raise NotImplementedError\n",
    "\n",
    "    @staticmethod\n",
    "    @abstractmethod\n",
    "    def calculate(self, df: DataFrame, col) -> Any:\n",
    "        \"Metodo executa metrica\"\n",
    "    \n",
    "    @staticmethod\n",
    "    @abstractmethod\n",
    "    def evaluate(self) -> Any:\n",
    "        \"Metodo executa metrica\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnMean(MetricBase, metaclass=CombineMeta):\n",
    "    \n",
    "    name: MetricName = MetricName.MEAN.value\n",
    "    type: MetricType = MetricType.COLUMN\n",
    "    schema: T.StructField = T.StructField(name, T.FloatType(), True)\n",
    "    \n",
    "    @classmethod\n",
    "    def calculate(cls):\n",
    "        print(type(cls.spark))\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate(*args, **kwargs):\n",
    "        print(*args) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnDuplicity(MetricBase, metaclass=CombineMeta):\n",
    "    \n",
    "    name: MetricName = MetricName.DUPLICITY.value\n",
    "    type: MetricType = MetricType.COLUMN\n",
    "    schema: T.StructField = T.StructField(name, T.FloatType(), True)\n",
    "    \n",
    "    @classmethod\n",
    "    def calculate(cls):\n",
    "        print(type(cls.spark))\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate(*args, **kwargs):\n",
    "        print(*args) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MEAN', 'DUPLICITY']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics = MetricBase.all_metrics()\n",
    "all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MetricType.COLUMN: 'COLUMN'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getattr(ColumnMean, \"type\")\n",
    "ColumnMean.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_schema = {\n",
    "    \"COLUNA\": T.StructField(\"COLUNA\", T.FloatType(), True),\n",
    "    MetricName.MEAN.value: T.StructField(MetricName.MEAN.value, T.FloatType(), True),\n",
    "    MetricName.DUPLICITY.value: T.StructField(MetricName.DUPLICITY.value, T.IntegerType(), True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---------+\n",
      "|COLUNA|MEAN|DUPLICITY|\n",
      "+------+----+---------+\n",
      "+------+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame([], schema=T.StructType(list(metrics_schema.values()))).createOrReplaceTempView(\"tb_metrics\")\n",
    "spark.table(\"tb_metrics\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"mrm.yaml\"\n",
    "\n",
    "with open(file_path) as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reference': {'database': 'workspace_db',\n",
       "  'table': 'tb_spec_dataset',\n",
       "  'train_data': {'start': 202001, 'end': 202212}},\n",
       " 'metrics': {'table': ['volumetria'],\n",
       "  'keys': {'names': ['pk_1', 'pk_2'],\n",
       "   'together': ['duplicidade'],\n",
       "   'individual': {'pk_1': ['ausencia'], 'pk_2': ['ausencia']}},\n",
       "  'features': {'numerigcal': {'col_a': ['media', 'moda', 'variancia'],\n",
       "    'col_b': ['media'],\n",
       "    'col_c': ['moda']},\n",
       "   'categorical': {'col_d': ['ausencia']}},\n",
       "  'target': {'target_name': ['distribuicao']}}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Measures = namedtuple(\"Measures\", all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MEAN', 'DUPLICITY')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Measures._fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = Measures(2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MEAN': 2, 'DUPLICITY': 0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1._asdict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+------+------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|target|tipo  |suit   |\n",
      "+------------+-----------+------------+-----------+------+------+-------+\n",
      "|5.1         |3.5        |1.4         |0.2        |0     |medium|Club   |\n",
      "|4.9         |3.0        |1.4         |0.2        |0     |low   |Diamond|\n",
      "|4.7         |3.2        |1.3         |0.2        |0     |low   |Club   |\n",
      "|4.6         |3.1        |1.5         |0.2        |0     |low   |Club   |\n",
      "|5.0         |3.6        |1.4         |0.2        |0     |low   |Heart  |\n",
      "+------------+-----------+------------+-----------+------+------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tenho um dicionario de entrada de uma funcao python e preciso que a saida seja no seguinte formato:\n",
    "\n",
    "input = {\n",
    "    'metrics': {\n",
    "        'table': ['volumetria'],\n",
    "        'keys': {\n",
    "            'names': ['id'],\n",
    "            'together': ['duplicidade'],\n",
    "            'individual': {\n",
    "                'id': ['ausencia']\n",
    "            }\n",
    "        },\n",
    "        'features': {\n",
    "            'numerigcal': {\n",
    "                'col_a': ['media'],\n",
    "                'col_b': ['media'],\n",
    "                'col_c': ['media']\n",
    "            },\n",
    "            'categorical': {\n",
    "                'col_d': ['ausencia']\n",
    "            }\n",
    "        },\n",
    "        'target': {\n",
    "            'target_name': ['ausencia']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "output = {\n",
    "    'ausencia': ['id', 'col_d', 'target_name'],\n",
    "    'duplicidade': ['together'],\n",
    "    'media': ['col_a', 'col_b', 'col_c']\n",
    "}\n",
    "\n",
    "\n",
    "Preciso agrupar individualmente os valores de cada lista com os valroes das chaves em um lista.\n",
    "Pensei em fazer tipo com uma funcao nested que trata os valroes lista e se for dicionario entra na propria funcao."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {\n",
    "    'metrics': {\n",
    "        'table': ['volumetria'],\n",
    "        'keys': {\n",
    "            'names': ['id'],\n",
    "            'together': ['duplicidade'],\n",
    "            'individual': {\n",
    "                'id': ['ausencia']\n",
    "            }\n",
    "        },\n",
    "        'features': {\n",
    "            'numerigcal': {\n",
    "                'col_a': ['media'],\n",
    "                'col_b': ['media'],\n",
    "                'col_c': ['media']\n",
    "            },\n",
    "            'categorical': {\n",
    "                'col_d': ['ausencia']\n",
    "            }\n",
    "        },\n",
    "        'target': {\n",
    "            'target_name': ['ausencia']\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {\n",
    "    'ausencia': ['id', 'col_d', 'target_name'],\n",
    "    'duplicidade': ['together'],\n",
    "    'media': ['col_a', 'col_b', 'col_c']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dict(d, output=None):\n",
    "    if output is None:\n",
    "        output = {}\n",
    "\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, dict):\n",
    "            process_dict(value, output)\n",
    "        elif isinstance(value, list):\n",
    "            for item in value:\n",
    "                if item not in output:\n",
    "                    output[item] = []\n",
    "                output[item].append(key)\n",
    "\n",
    "    return output\n",
    "\n",
    "def process_input(input_dict):\n",
    "    output = {}\n",
    "\n",
    "    # Process top-level 'metrics' dictionary\n",
    "    metrics_dict = input_dict.get('metrics', {})\n",
    "    process_dict(metrics_dict, output)\n",
    "\n",
    "    # Sort the lists in the output for consistency\n",
    "    for k, v in output.items():\n",
    "        output[k] = sorted(v)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'volumetria': ['table'], 'id': ['names'], 'duplicidade': ['together'], 'ausencia': ['col_d', 'id', 'target_name'], 'media': ['col_a', 'col_b', 'col_c']}\n"
     ]
    }
   ],
   "source": [
    "output = process_input(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itau",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
